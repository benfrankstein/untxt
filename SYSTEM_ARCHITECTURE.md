# OCR Platform - Complete System Architecture

## System Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              CLIENT / USER                                   â”‚
â”‚                      (Future: Web App / Desktop App)                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚                                                     â”‚
             â”‚ HTTP/REST API                                       â”‚ WebSocket
             â”‚ (File Upload)                                       â”‚ (Real-time)
             â–¼                                                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        BACKEND API SERVER (Node.js)                          â”‚
â”‚                          Port 8080 - Phase 3                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Routes: POST /api/tasks, GET /api/tasks/:id, etc.                  â”‚   â”‚
â”‚  â”‚  Services: S3, Database, Redis, WebSocket                           â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚              â”‚              â”‚                      â”‚
       â”‚ â‘ Upload      â”‚ â‘¡Store       â”‚ â‘¢Enqueue             â”‚ â‘©Send Updates
       â”‚ File         â”‚ Metadata     â”‚ Task                 â”‚
       â–¼              â–¼              â–¼                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              â”‚ â”‚            â”‚ â”‚              â”‚    â”‚   WebSocket     â”‚
â”‚   AWS S3     â”‚ â”‚ PostgreSQL â”‚ â”‚    Redis     â”‚    â”‚   Connections   â”‚
â”‚   Bucket     â”‚ â”‚  Database  â”‚ â”‚    Queue     â”‚    â”‚                 â”‚
â”‚              â”‚ â”‚            â”‚ â”‚              â”‚    â”‚  Connected      â”‚
â”‚  KMS-256     â”‚ â”‚  Port 5432 â”‚ â”‚  Port 6379   â”‚    â”‚  Clients        â”‚
â”‚  Encrypted   â”‚ â”‚            â”‚ â”‚              â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚              â”‚ â”‚  Tables:   â”‚ â”‚  Queues:     â”‚
â”‚  Hierarchy:  â”‚ â”‚  â€¢ files   â”‚ â”‚  â€¢ ocr:task: â”‚
â”‚  uploads/    â”‚ â”‚  â€¢ tasks   â”‚ â”‚    queue     â”‚
â”‚  {user_id}/  â”‚ â”‚  â€¢ users   â”‚ â”‚  â€¢ ocr:task: â”‚
â”‚  {YYYY-MM}/  â”‚ â”‚            â”‚ â”‚    processingâ”‚
â”‚  {file_id}/  â”‚ â”‚            â”‚ â”‚  â€¢ ocr:task: â”‚
â”‚  filename    â”‚ â”‚            â”‚ â”‚    results   â”‚
â”‚              â”‚ â”‚            â”‚ â”‚              â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚              â”‚                 â”‚
       â”‚ â‘£Download    â”‚ â‘¤Update         â”‚ â‘¥Dequeue
       â”‚ Input File   â”‚ Status          â”‚ Task (BRPOP)
       â”‚              â”‚                 â”‚
       â”‚              â”‚                 â”‚
       â–¼              â–¼                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         OCR WORKER (Python)                                  â”‚
â”‚                      Phase 2 - Background Process                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Components:                                                         â”‚   â”‚
â”‚  â”‚  â€¢ Task Processor (BRPOP listener)                                   â”‚   â”‚
â”‚  â”‚  â€¢ OCR Engine (Simulated Qwen3 - placeholder for real OCR)          â”‚   â”‚
â”‚  â”‚  â€¢ S3 Client (boto3)                                                 â”‚   â”‚
â”‚  â”‚  â€¢ Database Client (psycopg2)                                        â”‚   â”‚
â”‚  â”‚  â€¢ Redis Client                                                      â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚  Process:                                                            â”‚   â”‚
â”‚  â”‚  â‘¦ Download file from S3 to temp directory                           â”‚   â”‚
â”‚  â”‚  â‘§ Run OCR processing (simulate: generate HTML output)              â”‚   â”‚
â”‚  â”‚  â‘¨ Upload result HTML to S3                                          â”‚   â”‚
â”‚  â”‚  â‘© Update database with result metadata                             â”‚   â”‚
â”‚  â”‚  â‘ª Clean up temp files                                               â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                              â”‚
â”‚  Flask Health Monitor (Port 5000):                                           â”‚
â”‚  â€¢ GET /health - Worker health check                                         â”‚
â”‚  â€¢ GET /status - Queue and processing stats                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                       â”‚
                                       â”‚ â‘¨Upload Result
                                       â”‚
                                       â–¼
                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                              â”‚   AWS S3     â”‚
                              â”‚   results/   â”‚
                              â”‚   {user_id}/ â”‚
                              â”‚   {YYYY-MM}/ â”‚
                              â”‚   {file_id}/ â”‚
                              â”‚   result.htmlâ”‚
                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Complete Flow Explanation

### Phase 1: Data Layer (Infrastructure)
**Components:**
- PostgreSQL database (localhost:5432)
- Redis queue (localhost:6379)
- AWS S3 bucket with KMS encryption

**Purpose:** Persistent storage, task queuing, and file storage

---

### Phase 2: OCR Worker (Processing)
**Components:**
- Python worker process (background daemon)
- Flask health check server (localhost:5000)

**Purpose:** Process OCR tasks from the queue

---

### Phase 3: Backend API (Current Phase)
**Components:**
- Node.js Express server (localhost:8080)
- WebSocket server for real-time updates

**Purpose:** User-facing API for file upload and task management

---

## Step-by-Step Flow

### ğŸ“¤ UPLOAD FLOW (Steps 1-6)

**Step 1: Client Uploads File**
```bash
POST http://localhost:8080/api/tasks
Content-Type: multipart/form-data

{
  file: <binary data>,
  userId: "11111111-1111-1111-1111-111111111111",
  priority: 5
}
```

**Step 2: Backend Uploads to S3**
- Generates unique file_id and task_id (UUIDs)
- Creates hierarchical S3 key: `uploads/{user_id}/{YYYY-MM}/{file_id}/filename.pdf`
- Uploads file to S3 with KMS encryption (SSE-KMS)
- Calculates SHA-256 file hash for integrity

**Step 3: Backend Stores Metadata in PostgreSQL**
- Creates record in `files` table:
  ```sql
  INSERT INTO files (id, user_id, filename, mime_type, file_size,
                     s3_key, file_hash, status, uploaded_at)
  VALUES (file_id, user_id, 'document.pdf', 'application/pdf',
          1024000, 's3://...', 'sha256...', 'uploaded', NOW());
  ```

- Creates record in `tasks` table:
  ```sql
  INSERT INTO tasks (id, file_id, user_id, task_type, priority,
                     status, created_at)
  VALUES (task_id, file_id, user_id, 'ocr', 5, 'queued', NOW());
  ```

**Step 4: Backend Enqueues Task to Redis**
```python
# Redis command: LPUSH
LPUSH ocr:task:queue '{
  "task_id": "uuid...",
  "file_id": "uuid...",
  "user_id": "uuid...",
  "s3_key": "uploads/...",
  "filename": "document.pdf",
  "mime_type": "application/pdf",
  "priority": 5
}'
```

**Step 5: Backend Returns Response**
```json
{
  "success": true,
  "data": {
    "taskId": "abc-123-def",
    "fileId": "xyz-789-ghi",
    "filename": "document.pdf",
    "fileSize": 1024000,
    "mimeType": "application/pdf",
    "s3Key": "uploads/11111.../2025-10/abc-123.../document.pdf",
    "fileHash": "sha256...",
    "status": "queued",
    "queuePosition": 3,
    "createdAt": "2025-10-17T12:34:56.789Z"
  }
}
```

**Step 6: WebSocket Sends Initial Update**
```json
{
  "type": "task_update",
  "data": {
    "taskId": "abc-123-def",
    "status": "queued",
    "message": "Task queued for processing"
  },
  "timestamp": "2025-10-17T12:34:56.789Z"
}
```

---

### ğŸ”„ PROCESSING FLOW (Steps 7-11)

**Step 7: Worker Dequeues Task**
- Worker runs in infinite loop: `while True:`
- Blocks on Redis queue: `BRPOP ocr:task:queue 10` (10 second timeout)
- When task appears, worker receives it immediately

**Step 8: Worker Downloads File from S3**
```python
# Download to temp directory
temp_path = '/tmp/{task_id}/{filename}'
s3_client.download_file(
    bucket='untxt',
    key='uploads/11111.../document.pdf',
    filename=temp_path
)
```

**Step 9: Worker Updates Database (Processing)**
```sql
UPDATE tasks
SET status = 'processing',
    started_at = NOW()
WHERE id = task_id;
```

WebSocket update sent:
```json
{
  "type": "task_update",
  "data": {
    "taskId": "abc-123-def",
    "status": "processing",
    "message": "OCR processing started"
  }
}
```

**Step 10: Worker Runs OCR**
```python
# Currently simulated - will be replaced with real Qwen3 OCR
result_html = simulate_qwen3_ocr(temp_path)

# Example output:
"""
<html>
<head><title>OCR Result</title></head>
<body>
  <h1>Extracted Text</h1>
  <p>This is the text extracted from the document...</p>
  <div class="metadata">
    <p>Confidence: 98.5%</p>
    <p>Language: English</p>
  </div>
</body>
</html>
"""
```

**Step 11: Worker Uploads Result to S3**
```python
# Generate result S3 key
result_key = 'results/{user_id}/{YYYY-MM}/{file_id}/result.html'

# Upload HTML result
s3_client.upload_fileobj(
    fileobj=io.BytesIO(result_html.encode('utf-8')),
    bucket='untxt',
    key=result_key,
    extra_args={
        'ContentType': 'text/html',
        'ServerSideEncryption': 'aws:kms',
        'SSEKMSKeyId': 'arn:aws:kms:...'
    }
)
```

**Step 12: Worker Updates Database (Completed)**
```sql
-- Update file record
UPDATE files
SET s3_result_key = 'results/.../result.html',
    status = 'processed',
    updated_at = NOW()
WHERE id = file_id;

-- Update task record
UPDATE tasks
SET status = 'completed',
    result = '{"text_length": 1234, "confidence": 0.985}',
    completed_at = NOW()
WHERE id = task_id;
```

WebSocket update sent:
```json
{
  "type": "task_update",
  "data": {
    "taskId": "abc-123-def",
    "status": "completed",
    "message": "OCR processing completed successfully",
    "result": {
      "s3_result_key": "results/.../result.html",
      "text_length": 1234,
      "confidence": 0.985
    }
  }
}
```

**Step 13: Worker Cleans Up**
```python
# Remove temp files
os.remove(temp_path)
os.rmdir(os.path.dirname(temp_path))
```

---

### ğŸ“¥ DOWNLOAD FLOW (Retrieve Result)

**Step 14: Client Requests Result**
```bash
GET http://localhost:8080/api/tasks/{task_id}/result
```

**Step 15: Backend Generates Pre-signed URL**
```javascript
// Query database for result S3 key
const task = await db.query(
  'SELECT s3_result_key FROM files WHERE id = $1',
  [file_id]
);

// Generate pre-signed URL (expires in 1 hour)
const presignedUrl = await s3.getSignedUrl('getObject', {
  Bucket: 'untxt',
  Key: task.s3_result_key,
  Expires: 3600
});
```

**Step 16: Backend Returns Pre-signed URL**
```json
{
  "success": true,
  "data": {
    "taskId": "abc-123-def",
    "filename": "document.pdf",
    "resultUrl": "https://untxt.s3.amazonaws.com/results/...?X-Amz-Algorithm=...",
    "expiresIn": 3600
  }
}
```

**Step 17: Client Downloads Result**
```bash
# Direct download from S3 using pre-signed URL
curl -o result.html "https://untxt.s3.amazonaws.com/results/...?X-Amz-..."
```

---

## Key Features

### ğŸ”’ Security
- **KMS Encryption**: All files encrypted at rest in S3 using AWS KMS (AES-256)
- **Pre-signed URLs**: Temporary download links (1 hour expiry)
- **No Local Storage**: Files only in S3, temp files deleted after processing
- **Envelope Encryption**: S3 uses envelope encryption pattern

### âš¡ Performance
- **Async Processing**: Worker processes tasks in background
- **Redis Queue**: Fast, reliable task distribution
- **Connection Pooling**: PostgreSQL pool (max 20 connections)
- **Bucket Keys**: Reduces KMS API calls by 99%

### ğŸ“Š Real-time Updates
- **WebSocket**: Live task status updates
- **Server-Sent Events**: Optional for simple updates
- **Queue Monitoring**: Real-time queue length tracking

### ğŸ—ï¸ Scalability
- **Horizontal Scaling**: Add more workers for parallel processing
- **Queue-based**: Decoupled architecture for independent scaling
- **S3 Storage**: Unlimited file storage capacity
- **Stateless Backend**: Can run multiple backend instances

---

## Database Schema

### Files Table
```sql
CREATE TABLE files (
    id UUID PRIMARY KEY,
    user_id UUID NOT NULL,
    filename VARCHAR(255) NOT NULL,
    mime_type VARCHAR(100),
    file_size BIGINT,
    s3_key VARCHAR(500) UNIQUE NOT NULL,
    s3_result_key VARCHAR(500),
    file_hash VARCHAR(64),
    status VARCHAR(50) DEFAULT 'uploaded',
    uploaded_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW()
);
```

### Tasks Table
```sql
CREATE TABLE tasks (
    id UUID PRIMARY KEY,
    file_id UUID REFERENCES files(id),
    user_id UUID NOT NULL,
    task_type VARCHAR(50) DEFAULT 'ocr',
    priority INTEGER DEFAULT 5,
    status VARCHAR(50) DEFAULT 'queued',
    result JSONB,
    error_message TEXT,
    created_at TIMESTAMP DEFAULT NOW(),
    started_at TIMESTAMP,
    completed_at TIMESTAMP,
    updated_at TIMESTAMP DEFAULT NOW()
);
```

---

## Service Management

### Start All Services
```bash
./start_services.sh
```
Starts in order:
1. PostgreSQL (Phase 1)
2. Redis (Phase 1)
3. OCR Worker (Phase 2)
4. Flask Health Check (Phase 2)
5. Backend API (Phase 3)

### Stop All Services
```bash
./stop_services.sh
```
Stops in reverse order with graceful shutdown.

### Check Status
```bash
./status.sh
```
Shows status of all services and queue lengths.

---

## Testing

### Test Complete Flow
```bash
# Test task creation (upload â†’ queue â†’ database)
cd backend && ./test_task_creation.sh

# Test S3 upload/download round-trip
cd backend && ./test_s3_flow.sh

# Test WebSocket real-time updates
cd backend && node test_websocket.js
```

### Monitor Processing
```bash
# Watch worker logs
tail -f logs/worker.log

# Watch backend logs
tail -f logs/backend.log

# Check Redis queue
redis-cli LLEN ocr:task:queue

# Monitor task status in real-time
watch -n 1 "curl -s http://localhost:8080/api/tasks/{task_id}/status | python3 -m json.tool"
```

---

## Next Phases (Not Yet Implemented)

### Phase 4: Frontend (Next.js Web App)
- User interface for file upload
- Task list and status monitoring
- Result viewing and download
- User authentication

### Phase 5: Admin UI (Electron Desktop App)
- System monitoring dashboard
- Queue management
- User management
- Analytics and reporting

### Phase 6: Production Deployment
- Nginx reverse proxy
- SSL/TLS certificates
- Environment-based configuration
- IAM roles (replace access keys)
- AWS Secrets Manager

---

## Current Implementation Status

âœ… **Phase 1: Data Layer** - COMPLETE
- PostgreSQL with schema
- Redis queue
- S3 with KMS encryption

âœ… **Phase 2: OCR Worker** - COMPLETE
- Task processing loop
- S3 download/upload
- Database updates
- Flask health monitor

âœ… **Phase 3: Backend API** - COMPLETE
- REST API endpoints
- WebSocket server
- Task management
- Pre-signed URL generation

â³ **Phase 4: Frontend** - NOT STARTED

â³ **Phase 5: Admin UI** - NOT STARTED

â³ **Phase 6: Production** - NOT STARTED

---

## Architecture Highlights

### Cloud-Native Design
- No local file persistence
- S3 as single source of truth
- Stateless services for easy scaling

### Microservices Pattern
- Backend API (Node.js) - User-facing
- Worker (Python) - Processing
- Each can scale independently

### Async Processing
- Queue-based task distribution
- Non-blocking API responses
- Real-time status via WebSocket

### Security First
- KMS encryption at rest
- Temporary pre-signed URLs
- No credentials in files
- Environment-based configuration

---

## File Structure

```
untxt/
â”œâ”€â”€ backend/                    # Phase 3: Node.js Backend API
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ services/          # S3, DB, Redis, WebSocket
â”‚   â”‚   â”œâ”€â”€ routes/            # API endpoints
â”‚   â”‚   â”œâ”€â”€ config/            # Configuration
â”‚   â”‚   â”œâ”€â”€ app.js             # Express app
â”‚   â”‚   â””â”€â”€ index.js           # Server entry
â”‚   â”œâ”€â”€ test_*.sh              # Test scripts
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ .env                   # Config (DO NOT COMMIT)
â”‚
â”œâ”€â”€ worker/                     # Phase 2: Python OCR Worker
â”‚   â”œâ”€â”€ s3_client.py           # S3 operations
â”‚   â”œâ”€â”€ db_client.py           # Database operations
â”‚   â”œâ”€â”€ redis_client.py        # Redis operations
â”‚   â”œâ”€â”€ task_processor.py      # Main processing logic
â”‚   â”œâ”€â”€ run_worker.py          # Worker entry point
â”‚   â”œâ”€â”€ app.py                 # Flask health server
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ database/                   # Phase 1: Database Schema
â”‚   â””â”€â”€ scripts/
â”‚       â”œâ”€â”€ schema.sql
â”‚       â””â”€â”€ setup_database.sh
â”‚
â”œâ”€â”€ logs/                       # Runtime logs
â”‚   â”œâ”€â”€ backend.log
â”‚   â”œâ”€â”€ worker.log
â”‚   â””â”€â”€ flask.log
â”‚
â”œâ”€â”€ pids/                       # Process IDs
â”‚   â”œâ”€â”€ backend.pid
â”‚   â”œâ”€â”€ worker.pid
â”‚   â””â”€â”€ redis.pid
â”‚
â”œâ”€â”€ start_services.sh          # Start all services
â”œâ”€â”€ stop_services.sh           # Stop all services
â”œâ”€â”€ status.sh                  # Check status
â”‚
â””â”€â”€ docs/                       # Documentation
    â”œâ”€â”€ PRODUCTION_SECURITY.md
    â”œâ”€â”€ CURRENT_STATUS.md
    â””â”€â”€ development_order.md
```

---

## API Endpoints Reference

### Health Check
```
GET /health
Response: Service health status
```

### Create Task
```
POST /api/tasks
Body: multipart/form-data
  - file: <binary>
  - userId: <uuid>
  - priority: <1-10>
Response: Task created with ID
```

### List Tasks
```
GET /api/tasks?userId=<uuid>&limit=50&offset=0
Response: Array of tasks with pagination
```

### Get Task Details
```
GET /api/tasks/:taskId
Response: Task details with result URL if completed
```

### Get Task Status
```
GET /api/tasks/:taskId/status
Response: Current status (checks Redis, then DB)
```

### Get Task Result
```
GET /api/tasks/:taskId/result
Response: Pre-signed S3 URL for result HTML
```

### WebSocket Connection
```
ws://localhost:8080?userId=<uuid>
Messages:
  - connected: Initial connection
  - task_update: Real-time task updates
  - pong: Keepalive response
```

---

## Summary

This OCR platform implements a **production-ready, cloud-native, microservices architecture** with:

- **Secure file storage** (S3 + KMS encryption)
- **Reliable task processing** (Redis queue)
- **Persistent metadata** (PostgreSQL)
- **RESTful API** (Node.js + Express)
- **Real-time updates** (WebSocket)
- **Async processing** (Python worker)
- **Horizontal scalability** (stateless design)

The system is **fully functional** for Phases 1-3 and ready for frontend development (Phase 4).
